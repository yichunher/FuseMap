{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import anndata as ad\n",
    "import scanpy.external as sce\n",
    "from sklearn import preprocessing\n",
    "import pickle5 as pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "\n",
    "eps=1e-100\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### metrics from MARS\n",
    "import sklearn.metrics as metrics\n",
    "def compute_scores(y_true, y_pred, scoring={'accuracy','nmi',\n",
    "                                                'adj_rand','adj_mi',\n",
    "                                            'precision','recall','f1_score'}):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    scores = {}\n",
    "    set_scores(scores, y_true, y_pred, scoring)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "\n",
    "def set_scores(scores, y_true, y_pred, scoring):\n",
    "    labels=list(set(y_true))\n",
    "    \n",
    "    for metric in scoring:\n",
    "        if metric=='accuracy':\n",
    "            scores[metric] = metrics.accuracy_score(y_true, y_pred)\n",
    "        elif metric=='precision':\n",
    "            scores[metric] = metrics.precision_score(y_true, y_pred,  average='macro')\n",
    "        elif metric=='recall':\n",
    "            scores[metric] = metrics.recall_score(y_true, y_pred,  average='macro')\n",
    "        elif metric=='f1_score':\n",
    "            scores[metric] = metrics.f1_score(y_true, y_pred,  average='macro')\n",
    "        elif metric=='nmi':\n",
    "            scores[metric] = metrics.normalized_mutual_info_score(y_true, y_pred)\n",
    "        elif metric=='adj_mi':\n",
    "            scores[metric] = metrics.adjusted_mutual_info_score(y_true, y_pred)\n",
    "        elif metric=='adj_rand':\n",
    "            scores[metric] = metrics.adjusted_rand_score(y_true, y_pred)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_score={'method':[],'metrics':[],'value':[],'experiment':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238822f1",
   "metadata": {},
   "source": [
    "# FuseMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4934ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_embed_all=sc.read_h5ad(f\"source_data/FuseMap/base/transfer_celltype_starmap.h5ad\")\n",
    "\n",
    "query_data = sc.read_h5ad('source_data/query/vizgen_S1R3.h5ad')\n",
    "\n",
    "scores=compute_scores(query_data.obs['gtTaxonomyRank4'],\n",
    "                      ad_embed_all.obs['transfer_gtTaxonomyRank4_starmap'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('FuseMap')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ad3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_embed_all=sc.read_h5ad(f\"source_data/FuseMap/large/transfer_celltype_starmap.h5ad\")\n",
    "\n",
    "query_data = sc.read_h5ad('source_data/query/vizgen_S1R3.h5ad')\n",
    "\n",
    "scores=compute_scores(query_data.obs['gtTaxonomyRank4'],\n",
    "                      ad_embed_all.obs['transfer_gtTaxonomyRank4_starmap'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('FuseMap')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a887c392",
   "metadata": {},
   "source": [
    "# scanvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/scanvi/scanvi_e1.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['cell_type'],\n",
    "                      adata.obs['predictions'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('ScanVI')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/scanvi/scanvi_e3.h5ad')\n",
    "scores=compute_scores(adata.obs['cell_type'],\n",
    "                      adata.obs['predictions'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('ScanVI')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710f7f9b",
   "metadata": {},
   "source": [
    "# mars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/mars/adata_mars_all.h5ad')\n",
    "adata = adata[adata.obs['experiment']=='query',:]\n",
    "\n",
    "scores=compute_scores(adata.obs['truth_labels'],\n",
    "                      adata.obs['MARS_labels'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('MARS')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/mars/adata_mars_all_e3.h5ad')\n",
    "adata = adata[adata.obs['experiment']=='query',:]\n",
    "scores=compute_scores(adata.obs['truth_labels'],\n",
    "                      adata.obs['MARS_labels'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('MARS')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e1245",
   "metadata": {},
   "source": [
    "# scalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9333db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/scalex/scalex_adata_query.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      adata.obs['celltype_transfer'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('scalex')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee35896",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/scalex/scalex_adata_query_e3.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      adata.obs['celltype_transfer'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('scalex')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a3173a",
   "metadata": {},
   "source": [
    "# expiMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddc951",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/expimap/expimap_e1_mouseGOBP_ad_query.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      adata.obs['celltype_transfer'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('expiMap')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb99427",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/expimap/expimap_e3_mouseGOBP_ad_query.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      adata.obs['celltype_transfer'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('expiMap')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c593cdd",
   "metadata": {},
   "source": [
    "# scPoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/scpoli/scpoli_e1_query.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      adata.obs['cell_type_pred'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('scPoli')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/scpoli/scpoli_e3_query.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      adata.obs['cell_type_pred'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('scPoli')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080c151",
   "metadata": {},
   "source": [
    "# TOSICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ad4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/tosica/tosica_adata.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      adata.obs['Prediction'])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('TOSICA')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b891a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/tosica/e3_tosica_attn.h5ad')\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      adata.obs['Prediction'])\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('TOSICA')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d08bb",
   "metadata": {},
   "source": [
    "# Concerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b044211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/concerto/adata_concerto.h5ad')\n",
    "adata=adata[adata.obs['batch']=='query',:]\n",
    "\n",
    "with (open('source_data/concerto/query_neighbor.pkl', \"rb\")) as openfile:\n",
    "    query_neighbor = pickle.load(openfile)\n",
    "    \n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      query_neighbor)\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('Concerto')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/concerto/adata_concerto_e3.h5ad')\n",
    "adata=adata[adata.obs['batch']=='query',:]\n",
    "\n",
    "with (open('source_data/concerto/query_neighbor_e3.pkl', \"rb\")) as openfile:\n",
    "    query_neighbor = pickle.load(openfile)\n",
    "    \n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      query_neighbor)\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('Concerto')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d550265",
   "metadata": {},
   "source": [
    "# itClust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56e47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/tosica/tosica_adata.h5ad')\n",
    "\n",
    "clustering_results = pd.read_csv('source_data/itclust/clustering_results.csv',index_col=0)\n",
    "\n",
    "itclust_name = {0:'Astrocytes', 1:'Cerebellum neurons', 2:'Cholinergic and monoaminergic neurons', \n",
    " 3:'Choroid epithelial cells', 4:'Dentate gyrus granule neurons', 5:'Dentate gyrus radial glia-like cells',\n",
    " 6:'Di- and mesencephalon excitatory neurons',7:'Di- and mesencephalon inhibitory neurons',\n",
    " 8:'Enteric glia',\n",
    "9:'Ependymal cells',10:'Glutamatergic neuroblasts',11:'Hindbrain neurons',\n",
    " 12:'Microglia',13:'Non-glutamatergic neuroblasts',14:'Olfactory ensheathing cells',\n",
    " 15:'Olfactory inhibitory neurons',16:'Oligodendrocyte precursor cells'}\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      [itclust_name[i] for i in clustering_results['cluster']])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('ItClust')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('source_data/tosica/tosica_adata.h5ad')\n",
    "clustering_results = pd.read_csv('source_data/itclust/itclust_pred_e3.csv',index_col=0)\n",
    "\n",
    "itclust_name = {0:'Astrocytes', 1:'Cerebellum neurons', 2:'Cholinergic and monoaminergic neurons', \n",
    " 3:'Choroid epithelial cells'}\n",
    "\n",
    "scores=compute_scores(adata.obs['gtTaxonomyRank4'],\n",
    "                      [itclust_name[i] for i in clustering_results['cluster']])\n",
    "\n",
    "for i in scores.keys():\n",
    "    dict_score['method'].append('ItClust')\n",
    "    dict_score['metrics'].append(i)\n",
    "    dict_score['value'].append(scores[i])\n",
    "    dict_score['experiment'].append('large_pretrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc5c8ac",
   "metadata": {},
   "source": [
    "### plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6f1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_score_o=pd.DataFrame(dict_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251c3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orderlist = ['FuseMap', 'Concerto', 'ScanVI','expiMap', 'TOSICA', 'ItClust','MARS','scPoli','scalex',]\n",
    "\n",
    "color_paleet=sns.color_palette('Paired')\n",
    "mpl.rcParams[\"axes.spines.right\"] = False\n",
    "mpl.rcParams[\"axes.spines.top\"] = False\n",
    "\n",
    "for metric in ['accuracy','adj_mi','adj_rand',  'f1_score','precision', 'recall', ]:\n",
    "    df=dict_score_o.loc[dict_score_o['metrics']==metric,:].copy()\n",
    "    \n",
    "    height1 = [list(df.loc[(df['experiment']=='base') & (df['method']==i),'value'])[0] for i in orderlist]\n",
    "    height2 = [list(df.loc[(df['experiment']!='base') & (df['method']==i),'value'])[0] for i in orderlist]\n",
    "\n",
    "    # set width of bar\n",
    "    barWidth = 0.4\n",
    "    fig = plt.subplots(figsize =(3, 4))\n",
    "\n",
    "    # Set position of bar on X axis\n",
    "    br1 = np.arange(len(orderlist))\n",
    "    br2 = [x + barWidth for x in br1]\n",
    "\n",
    "    # Make the plot\n",
    "    plt.bar(br1, height1, width = barWidth,color=color_paleet,lw=0.3,\n",
    "            edgecolor ='k', hatch='///')\n",
    "    plt.bar(br2, height2,  width = barWidth,color=color_paleet,lw=0.3,\n",
    "            edgecolor ='k')\n",
    "\n",
    "    plt.xticks([r + barWidth for r in range(len(orderlist))],\n",
    "            orderlist,rotation=90)\n",
    "    plt.ylim([0,0.8])\n",
    "    plt.legend('',frameon=False)\n",
    "    \n",
    "#     plt.savefig(f\"benchmark/figures/celltype_all/{metric}.pdf\", dpi=300, transparent=True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
